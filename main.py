import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR
from tkinter import Tk, filedialog

# 1. Kh·ªüi t·∫°o
yolo_model = YOLO("Bienso.pt")
# Kh·ªüi t·∫°o PaddleOCR v·ªõi c·∫•u h√¨nh ·ªïn ƒë·ªãnh
ocr = PaddleOCR(use_angle_cls=True, lang='en')


def select_file():
    root = Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    path = filedialog.askopenfilename(title="Ch·ªçn ·∫£nh bi·ªÉn s·ªë xe")
    root.destroy()
    return path


image_path = select_file()
if not image_path: exit()

img = cv2.imread(image_path)
results = yolo_model(img)[0]

if len(results.boxes.xyxy) == 0:
    print("‚ùå YOLO kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë.")
else:
    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt bi·ªÉn s·ªë (n·ªõi r·ªông 2px ƒë·ªÉ tr√°nh m·∫•t n√©t)
        crop = img[max(0, y1 - 2):min(img.shape[0], y2 + 2),
        max(0, x1 - 2):min(img.shape[1], x2 + 2)]
        if crop.size == 0: continue

        # --- TI·ªÄN X·ª¨ L√ù ---
        h, w = crop.shape[:2]
        crop = cv2.resize(crop, (w * 3, h * 3), interpolation=cv2.INTER_LANCZOS4)
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)

        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        gray = cv2.GaussianBlur(gray, (3, 3), 0)
        ocr_input = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)

        # --- NH·∫¨N DI·ªÜN (S·ª¨A L·ªñI T·∫†I ƒê√ÇY) ---
        # S·ª≠ d·ª•ng ocr.ocr() nh∆∞ng truy xu·∫•t theo c·∫•u tr√∫c an to√†n
        output = ocr.ocr(ocr_input)

        plate_text = ""
        if output and output[0]:
            for line in output[0]:
                # Ki·ªÉm tra ch·∫Øc ch·∫Øn line c√≥ c·∫•u tr√∫c: [ [box], (text, confidence) ]
                if isinstance(line, list) and len(line) > 1:
                    data = line[1]  # L·∫•y ph·∫ßn (text, confidence)
                    if isinstance(data, tuple) and len(data) > 1:
                        text = data[0]
                        conf = data[1]

                        if conf > 0.4:
                            print(f"--- AI th·∫•y: {text} ({round(conf, 2)})")
                            plate_text += text

            # L√†m s·∫°ch k·∫øt qu·∫£
            plate_text = re.sub(r'[^0-9A-Z]', '', plate_text.upper())
            # S·ª≠a l·ªói nh·∫≠n di·ªán nh·∫ßm k√Ω t·ª± th∆∞·ªùng g·∫∑p
            mapping = {'S': '5', 'G': '6', 'O': '0', 'D': '0'}
            for char, replace_char in mapping.items():
                # Ch·ªâ thay th·∫ø ·ªü nh·ªØng v·ªã tr√≠ h·ª£p l√Ω (v√≠ d·ª• ƒë·∫ßu bi·ªÉn th∆∞·ªùng l√† s·ªë)
                if plate_text.startswith(char):
                    plate_text = replace_char + plate_text[1:]

            print(f"‚úÖ K·∫æT QU·∫¢ CU·ªêI: {plate_text}")

            # V·∫Ω l√™n ·∫£nh
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, plate_text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

cv2.imshow("Result", img)
cv2.waitKey(0)
cv2.destroyAllWindows()






'''

import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR

# 1Ô∏è‚É£ Kh·ªüi t·∫°o models
yolo_bienso = YOLO("Bienso.pt")
# D√πng lang='ch' ƒë·ªÉ tr√°nh l·ªói EEEE t·ªët h∆°n
ocr = PaddleOCR(lang='ch', use_textline_orientation=False)

# 2Ô∏è‚É£ M·ªü Camera (0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)
cap = cv2.VideoCapture(0)

# C·∫•u h√¨nh ƒë·ªô ph√¢n gi·∫£i camera (T√πy ch·ªçn)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

print("--- ƒêang m·ªü Camera... Nh·∫•n 'q' ƒë·ªÉ tho√°t ---")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # 3Ô∏è‚É£ YOLO Detect tr√™n t·ª´ng khung h√¨nh
    # imgsz=416 gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω real-time
    results = yolo_bienso(frame, conf=0.5, imgsz=416)[0]

    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt ·∫£nh bi·ªÉn s·ªë
        crop = frame[y1:y2, x1:x2]
        if crop.size == 0: continue

        # --- X·ª¨ L√ù NHI·ªÑU (T·ªëi ∆∞u cho Camera) ---
        h_c, w_c = crop.shape[:2]
        margin_h = int(h_c * 0.1)
        margin_w = int(w_c * 0.05)
        crop = crop[margin_h:h_c - margin_h, margin_w:w_c - margin_w]

        # Ph√≥ng to v√† x·ª≠ l√Ω ƒêen - Tr·∫Øng
        crop_res = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)
        
        # TƒÉng t∆∞∆°ng ph·∫£n nhanh
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        ocr_input = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # 4Ô∏è‚É£ OCR NH·∫¨N DI·ªÜN
        # L∆∞u √Ω: OCR t·ªën t√†i nguy√™n, trong th·ª±c t·∫ø c√≥ th·ªÉ d√πng lu·ªìng (threading) 
        # nh∆∞ng ·ªü ƒë√¢y d√πng tr·ª±c ti·∫øp ƒë·ªÉ b·∫°n d·ªÖ hi·ªÉu
        prediction = ocr.predict(ocr_input)
        ocr_rs = list(prediction)

        plate_text = ""
        if ocr_rs and ocr_rs[0]:
            raw_text = "".join([line[1][0] for line in ocr_rs[0]])
            plate_text = re.sub(r'[^0-9A-Z]', '', raw_text.upper())
            
            # L·ªçc nhi·ªÖu
            for noise in ["NAO", "TO", "EEEE", "IEE", "NONE"]:
                plate_text = plate_text.replace(noise, "")

            # V·∫Ω khung v√† ch·ªØ l√™n khung h√¨nh Camera
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"LP: {plate_text}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # In k·∫øt qu·∫£ ra console
            if plate_text:
                print(f"üì∑ Camera Detect: {plate_text}")

    # 5Ô∏è‚É£ Hi·ªÉn th·ªã khung h√¨nh Camera
    cv2.imshow("Nhan dien Bien so Real-time", frame)

    # Nh·∫•n 'q' ƒë·ªÉ tho√°t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
'''