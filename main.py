import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
import easyocr
from tkinter import Tk, filedialog

# 1. Kh·ªüi t·∫°o Models
yolo_model = YOLO("Bienso.pt")
reader = easyocr.Reader(['en'], gpu=False)


def select_file():
    root = Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    path = filedialog.askopenfilename(title="Ch·ªçn ·∫£nh bi·ªÉn s·ªë xe")
    root.destroy()
    return path


def vietnamese_plate_correction(text):
    """H√†m s·ª≠a l·ªói d·ª±a tr√™n logic ƒë·ªãnh d·∫°ng bi·ªÉn s·ªë VN"""
    text = re.sub(r'[^0-9A-Z]', '', text.upper())
    if len(text) < 7: return text

    chars = list(text)
    # Quy t·∫Øc: K√Ω t·ª± th·ª© 3 (index 2) th∆∞·ªùng l√† CH·ªÆ (K, L, M, N...)
    map_to_char = {'1': 'I', '7': 'T', '0': 'O', '5': 'S', '2': 'Z'}
    if chars[2].isdigit():
        chars[2] = map_to_char.get(chars[2], chars[2])

    # Quy t·∫Øc: K√Ω t·ª± th·ª© 4 (index 3) th∆∞·ªùng l√† S·ªê
    map_to_num = {'I': '1', 'T': '7', 'S': '5', 'G': '6', 'B': '8', 'D': '0'}
    if not chars[3].isdigit():
        chars[3] = map_to_num.get(chars[3], chars[3])

    return "".join(chars)


image_path = select_file()
if not image_path: exit()

img = cv2.imread(image_path)
results = yolo_model.predict(img, conf=0.5)[0]

if len(results.boxes) == 0:
    print("‚ùå YOLO kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë.")
else:
    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # 1. Padding n·ªõi r·ªông v√πng c·∫Øt
        pad_h = int((y2 - y1) * 0.15)
        pad_w = int((x2 - x1) * 0.10)
        crop = img[max(0, y1 - pad_h):min(img.shape[0], y2 + pad_h),
        max(0, x1 - pad_w):min(img.shape[1], x2 + pad_w)]
        if crop.size == 0: continue

        # 2. Ti·ªÅn x·ª≠ l√Ω n√¢ng cao
        crop_res = cv2.resize(crop, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_LANCZOS4)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)

        # C√¢n b·∫±ng s√°ng
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # --- B∆Ø·ªöC QUAN TR·ªåNG: L√ÄM N√âT C·∫†NH (Gi√∫p ph√¢n bi·ªát 7/1) ---
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)

        cv2.imshow(f"AI nhin thay {idx}", sharpened)

        # 3. Nh·∫≠n di·ªán
        ocr_results = reader.readtext(sharpened, detail=1)

        # S·∫Øp x·∫øp theo t·ªça ƒë·ªô X tr∆∞·ªõc (t·ª´ tr√°i sang ph·∫£i)
        # sau ƒë√≥ m·ªõi theo t·ªça ƒë·ªô Y (t·ª´ tr√™n xu·ªëng d∆∞·ªõi)
        ocr_results.sort(key=lambda x: (x[0][0][1] // 10, x[0][0][0]))

        plate_parts = []
        for (bbox, text, prob) in ocr_results:
            if prob > 0.2:
                # Ch·ªâ l·∫•y ch·ªØ v√† s·ªë, b·ªè d·∫•u g·∫°ch, d·∫•u ch·∫•m
                clean_part = re.sub(r'[^0-9A-Z]', '', text.upper())
                plate_parts.append(clean_part)

        raw_plate = "".join(plate_parts)

        # 4. H·∫≠u x·ª≠ l√Ω th√¥ng minh (Fix l·ªói 1/7, 5/6 nh∆∞ng kh√¥ng l√†m m·∫•t chu·ªói)
        final_text = raw_plate
        if len(final_text) >= 7:
            chars = list(final_text)
            # Fix l·ªói s·ªë 1 v√† 7 ph·ªï bi·∫øn
            map_to_num = {'I': '1', 'T': '7', 'S': '5', 'G': '6', 'B': '8', 'D': '0'}
            # Th·ª≠ fix c√°c v·ªã tr√≠ ch·∫Øc ch·∫Øn l√† s·ªë (th∆∞·ªùng l√† c√°c v·ªã tr√≠ cu·ªëi)
            for i in range(len(chars) - 1, len(chars) - 4, -1):
                if not chars[i].isdigit():
                    chars[i] = map_to_num.get(chars[i], chars[i])
            final_text = "".join(chars)

        print(f"‚úÖ K·∫æT QU·∫¢ CU·ªêI: {final_text}")

        # --- V·∫º L√äN ·∫¢NH ---
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.rectangle(img, (x1, y1 - 35), (x1 + 250, y1), (0, 255, 0), -1)
        cv2.putText(img, final_text, (x1 + 5, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)

cv2.imshow("Anh dau vao", img)
cv2.waitKey(0)
cv2.destroyAllWindows()


'''

import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR

# 1Ô∏è‚É£ Kh·ªüi t·∫°o models
yolo_bienso = YOLO("Bienso.pt")
# D√πng lang='ch' ƒë·ªÉ tr√°nh l·ªói EEEE t·ªët h∆°n
ocr = PaddleOCR(lang='ch', use_textline_orientation=False)

# 2Ô∏è‚É£ M·ªü Camera (0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)
cap = cv2.VideoCapture(0)

# C·∫•u h√¨nh ƒë·ªô ph√¢n gi·∫£i camera (T√πy ch·ªçn)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

print("--- ƒêang m·ªü Camera... Nh·∫•n 'q' ƒë·ªÉ tho√°t ---")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # 3Ô∏è‚É£ YOLO Detect tr√™n t·ª´ng khung h√¨nh
    # imgsz=416 gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω real-time
    results = yolo_bienso(frame, conf=0.5, imgsz=416)[0]

    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt ·∫£nh bi·ªÉn s·ªë
        crop = frame[y1:y2, x1:x2]
        if crop.size == 0: continue

        # --- X·ª¨ L√ù NHI·ªÑU (T·ªëi ∆∞u cho Camera) ---
        h_c, w_c = crop.shape[:2]
        margin_h = int(h_c * 0.1)
        margin_w = int(w_c * 0.05)
        crop = crop[margin_h:h_c - margin_h, margin_w:w_c - margin_w]

        # Ph√≥ng to v√† x·ª≠ l√Ω ƒêen - Tr·∫Øng
        crop_res = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)
        
        # TƒÉng t∆∞∆°ng ph·∫£n nhanh
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        ocr_input = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # 4Ô∏è‚É£ OCR NH·∫¨N DI·ªÜN
        # L∆∞u √Ω: OCR t·ªën t√†i nguy√™n, trong th·ª±c t·∫ø c√≥ th·ªÉ d√πng lu·ªìng (threading) 
        # nh∆∞ng ·ªü ƒë√¢y d√πng tr·ª±c ti·∫øp ƒë·ªÉ b·∫°n d·ªÖ hi·ªÉu
        prediction = ocr.predict(ocr_input)
        ocr_rs = list(prediction)

        plate_text = ""
        if ocr_rs and ocr_rs[0]:
            raw_text = "".join([line[1][0] for line in ocr_rs[0]])
            plate_text = re.sub(r'[^0-9A-Z]', '', raw_text.upper())
            
            # L·ªçc nhi·ªÖu
            for noise in ["NAO", "TO", "EEEE", "IEE", "NONE"]:
                plate_text = plate_text.replace(noise, "")

            # V·∫Ω khung v√† ch·ªØ l√™n khung h√¨nh Camera
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"LP: {plate_text}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # In k·∫øt qu·∫£ ra console
            if plate_text:
                print(f"üì∑ Camera Detect: {plate_text}")

    # 5Ô∏è‚É£ Hi·ªÉn th·ªã khung h√¨nh Camera
    cv2.imshow("Nhan dien Bien so Real-time", frame)

    # Nh·∫•n 'q' ƒë·ªÉ tho√°t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
'''