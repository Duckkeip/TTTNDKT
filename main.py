import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
import easyocr
from tkinter import Tk, filedialog
from datetime import datetime
import unicodedata
# =========================
# QUALITY CHECK & ENHANCE
# =========================

def is_blurry(image, thresh=80):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    fm = cv2.Laplacian(gray, cv2.CV_64F).var()
    return fm < thresh, fm

def is_dark(image, thresh=60):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean = np.mean(gray)
    return mean < thresh, mean

def remove_shadow(img):
    rgb_planes = cv2.split(img)
    result_planes = []

    for plane in rgb_planes:
        dilated = cv2.dilate(plane, np.ones((7,7), np.uint8))
        bg = cv2.medianBlur(dilated, 21)
        diff = 255 - cv2.absdiff(plane, bg)
        result_planes.append(diff)

    result = cv2.merge(result_planes)
    return cv2.normalize(result, None, 0, 255, cv2.NORM_MINMAX)

def enhance_image(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(3.0, (8,8))
    cl1 = clahe.apply(gray)
    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
    sharp = cv2.filter2D(cl1, -1, kernel)
    return sharp


# =========================
# 1. KH·ªûI T·∫†O MODEL
# =========================
yolo_plate = YOLO("Bienso.pt")
yolo_sv    = YOLO("Thesv.pt")
reader = easyocr.Reader(['vi','en'], gpu=False)

# =========================
# 2. CH·ªåN ·∫¢NH
# =========================
def select_file():
    root = Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    path = filedialog.askopenfilename(title="Ch·ªçn ·∫£nh")
    root.destroy()
    return path

# =========================
# 3. S·ª¨A L·ªñI BI·ªÇN S·ªê
# =========================
def vietnamese_plate_correction(text):
    text = re.sub(r'[^0-9A-Z]', '', text.upper())
    if len(text) < 7:
        return text

    chars = list(text)

    map_to_char = {'1': 'I', '7': 'T', '0': 'O', '5': 'S', '2': 'Z'}
    map_to_num  = {'I': '1', 'T': '7', 'S': '5', 'G': '6', 'B': '8', 'D': '0', 'O':'0'}

    if len(chars) > 2 and chars[2].isdigit():
        chars[2] = map_to_char.get(chars[2], chars[2])

    if len(chars) > 3 and not chars[3].isdigit():
        chars[3] = map_to_num.get(chars[3], chars[3])

    for i in range(len(chars)-1, max(len(chars)-4, 3), -1):
        if not chars[i].isdigit():
            chars[i] = map_to_num.get(chars[i], chars[i])

    return "".join(chars)

# =========================
# 4. MAIN
# =========================
image_path = select_file()
if not image_path:
    print("‚ùå Ch∆∞a ch·ªçn ·∫£nh")
    exit()

img = cv2.imread(image_path)

plate_results = yolo_plate.predict(img, conf=0.5)[0]
sv_results    = yolo_sv.predict(img, conf=0.5)[0]
if len(sv_results.boxes) == 0:
    print("‚ö† KH√îNG PH√ÅT HI·ªÜN TH·∫∫ SINH VI√äN HO·∫∂C KHU√îN M·∫∂T")

if len(plate_results.boxes) == 0:
    print("‚ö† KH√îNG PH√ÅT HI·ªÜN BI·ªÇN S·ªê")
os.makedirs("plates", exist_ok=True)
os.makedirs("sv_cards", exist_ok=True)

def normalize_text(text):
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    text = text.upper()
    text = re.sub(r"[^A-Z0-9/ ]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()
def extract_student_info(ocr_text):
    data = {
        "school": "",
        "name": "",
        "student_id": "",
        "major": "",
        "year": "",
        "dob": "",  # ‚úÖ ng√†y sinh
        "dates": []
    }

    text = normalize_text(ocr_text)
    # üéÇ DATE OF BIRTH / NG√ÄY SINH (∆∞u ti√™n c√≥ nh√£n)
    dob_match = re.search(
        r"(NGAY SINH|DOB|DATE OF BIRTH)\s*[: ]*\s*(\d{1,2}/\d{1,2}/\d{2,4})",
        text
    )

    if dob_match:
        data["dob"] = dob_match.group(2)
    else:
        # fallback: l·∫•y ng√†y d·∫°ng dd/mm/yyyy
        full_dates = re.findall(r"\b\d{1,2}/\d{1,2}/\d{4}\b", text)
        if full_dates:
            data["dob"] = full_dates[0]

    # üéì Tr∆∞·ªùng
    if "HOC VIEN HANG KHONG" in text or "H·ªåC VI·ªÜN H√ÄNG KH√îNG" in text:
        data["school"] = "H·ªåC VI·ªÜN H√ÄNG KH√îNG VI·ªÜT NAM"

    # üÜî MSSV (>=8 s·ªë)
    ids = re.findall(r"\b\d{8,11}\b", text)
    if ids:
        data["student_id"] = ids[0]

    # üìÖ NƒÉm
    years = re.findall(r"\b20\d{2}\b", text)
    if years:
        data["year"] = years[0]

    # üìÜ Ng√†y
    data["dates"] = re.findall(r"\b\d{1,2}/\d{1,2}\b", text)

    # üìö NG√ÄNH (b·∫Øt theo t·ª´ kh√≥a)
    if ("CONG" in text and "NGHE" in text and "THONG" in text) or \
       ("NGHE" in text and "TIN" in text):
        data["major"] = "C√îNG NGH·ªÜ TH√îNG TIN"
    elif "HANG KHONG" in text:
        data["major"] = "H√ÄNG KH√îNG"

    # üë§ H·ªå T√äN (ch·ªãu l·ªói OCR)
    name_patterns = [
        r"HO.?V.?TEN[:\s]+([A-Z\s]+)",
        r"HO.?VA.?TEN[:\s]+([A-Z\s]+)",
        r"HOVATEN[:\s]+([A-Z\s]+)"
    ]

    for p in name_patterns:
        m = re.search(p, text)
        if m:
            name = m.group(1)
            name = re.sub(r"(MSSV|MA SV|NGANH|KHOA|SINH VIEN|THE).*", "", name)
            name = re.sub(r"\s+", " ", name).strip()
            data["name"] = name.title()
            break

    return data

# =========================
# 5. NH·∫¨N DI·ªÜN BI·ªÇN S·ªê
# =========================
print("\nüöó ===== NH·∫¨N DI·ªÜN BI·ªÇN S·ªê =====")

for idx, box in enumerate(plate_results.boxes):

    x1, y1, x2, y2 = map(int, box.xyxy[0])
    yolo_conf = float(box.conf[0])

    pad_h = int((y2 - y1) * 0.15)
    pad_w = int((x2 - x1) * 0.10)

    crop = img[max(0, y1-pad_h):min(img.shape[0], y2+pad_h),
               max(0, x1-pad_w):min(img.shape[1], x2+pad_w)]

    if crop.size == 0:
        continue

    crop = cv2.resize(crop, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_LANCZOS4)
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)

    clahe = cv2.createCLAHE(2.0, (8,8))
    enhanced = clahe.apply(gray)

    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
    sharpened = cv2.filter2D(enhanced, -1, kernel)

    cv2.imwrite(f"plates/plate_{idx}.jpg", sharpened)

    ocr_results = reader.readtext(sharpened, detail=1)
    ocr_results.sort(key=lambda x: (x[0][0][1]//10, x[0][0][0]))

    plate_parts = []
    conf_list = []

    for (bbox, text, prob) in ocr_results:
        if prob > 0.2:
            clean = re.sub(r'[^0-9A-Z]', '', text.upper())
            if clean:
                plate_parts.append(clean)
                conf_list.append(prob)

    raw_plate = "".join(plate_parts)
    ocr_conf = np.mean(conf_list) if conf_list else 0

    fixed_plate = vietnamese_plate_correction(raw_plate)
    final_conf = round((yolo_conf*0.5 + ocr_conf*0.5)*100, 2)

    is_valid = bool(re.match(r'^\d{2}[A-Z]\d{4,5}$', fixed_plate))

    if final_conf < 35 or len(fixed_plate) < 7:
        continue

    print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    print(f"üìå Plate : {fixed_plate}")
    print(f"üéØ FINAL : {final_conf}%")
    print(f"üáªüá≥ Check: {'H·ª¢P L·ªÜ' if is_valid else 'NGHI NG·ªú'}")

    cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)
    cv2.rectangle(img, (x1, y1-40), (x1+380, y1), (0,255,0), -1)
    cv2.putText(img, f"{fixed_plate} | {final_conf}%", (x1+5, y1-12),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)

# =========================
# 6. NH·∫¨N DI·ªÜN TH·∫∫ SINH VI√äN
# =========================
print("\nüéì ===== NH·∫¨N DI·ªÜN TH·∫∫ SINH VI√äN =====")

names = yolo_sv.names  # {0:'the', 1:'mat'}

for idx, box in enumerate(sv_results.boxes):

    x1, y1, x2, y2 = map(int, box.xyxy[0])
    conf = float(box.conf[0])
    cls_id = int(box.cls[0])
    cls_name = names[cls_id]

    crop = img[y1:y2, x1:x2]
    if crop.size == 0:
        continue

    # ================= FACE =================
    if cls_name == "mat":
        os.makedirs("faces", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        cv2.imwrite(f"faces/face_{timestamp}_{idx}.jpg", crop)

        print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print(f"üôÇ Khu√¥n m·∫∑t #{idx}")
        print(f"üì¶ YOLO : {conf:.2f}")

        cv2.rectangle(img, (x1,y1), (x2,y2), (0,0,255), 2)
        cv2.putText(img, "KHUON MAT", (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)

    # ================= STUDENT CARD =================
    elif cls_name == "the":
        os.makedirs("sv_cards", exist_ok=True)
        cv2.imwrite(f"sv_cards/card_{idx}.jpg", crop)

        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        gray = cv2.GaussianBlur(gray, (3,3), 0)
        thresh = cv2.adaptiveThreshold(gray,255,
                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                        cv2.THRESH_BINARY,11,2)

        ocr_sv = reader.readtext(thresh, detail=1)

        texts = []
        for (bbox, text, prob) in ocr_sv:
            if prob > 0.3:
                texts.append(text)

        full_text = " | ".join(texts)
        info = extract_student_info(full_text)

        print("üéØ TR√çCH TH√îNG TIN:")
        for k, v in info.items():
            print(f"   {k.upper():10}: {v}")
        print("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print(f"üéì Th·∫ª SV #{idx}")
        print(f"üì¶ YOLO : {conf:.2f}")
        print(f"ü™™ OCR  : {full_text}")

        cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)
        cv2.rectangle(img, (x1, y1-30), (x1+300, y1), (255,0,0), -1)
        label = f"{info['student_id']} - {info['name'][:20]}"
        cv2.rectangle(img, (x1, y1 - 35), (x1 + 480, y1), (255, 0, 0), -1)
        cv2.putText(img, label, (x1 + 5, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

# =========================
# 7. HI·ªÇN TH·ªä K·∫æT QU·∫¢
# =========================
cv2.imshow("KET QUA", img)
cv2.imwrite("result.jpg", img)
cv2.waitKey(0)
cv2.destroyAllWindows()


'''

import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR

# 1Ô∏è‚É£ Kh·ªüi t·∫°o models
yolo_bienso = YOLO("Bienso.pt")
# D√πng lang='ch' ƒë·ªÉ tr√°nh l·ªói EEEE t·ªët h∆°n
ocr = PaddleOCR(lang='ch', use_textline_orientation=False)

# 2Ô∏è‚É£ M·ªü Camera (0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)
cap = cv2.VideoCapture(0)

# C·∫•u h√¨nh ƒë·ªô ph√¢n gi·∫£i camera (T√πy ch·ªçn)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

print("--- ƒêang m·ªü Camera... Nh·∫•n 'q' ƒë·ªÉ tho√°t ---")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # 3Ô∏è‚É£ YOLO Detect tr√™n t·ª´ng khung h√¨nh
    # imgsz=416 gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω real-time
    results = yolo_bienso(frame, conf=0.5, imgsz=416)[0]

    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt ·∫£nh bi·ªÉn s·ªë
        crop = frame[y1:y2, x1:x2]
        if crop.size == 0: continue

        # --- X·ª¨ L√ù NHI·ªÑU (T·ªëi ∆∞u cho Camera) ---
        h_c, w_c = crop.shape[:2]
        margin_h = int(h_c * 0.1)
        margin_w = int(w_c * 0.05)
        crop = crop[margin_h:h_c - margin_h, margin_w:w_c - margin_w]

        # Ph√≥ng to v√† x·ª≠ l√Ω ƒêen - Tr·∫Øng
        crop_res = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)
        
        # TƒÉng t∆∞∆°ng ph·∫£n nhanh
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        ocr_input = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # 4Ô∏è‚É£ OCR NH·∫¨N DI·ªÜN
        # L∆∞u √Ω: OCR t·ªën t√†i nguy√™n, trong th·ª±c t·∫ø c√≥ th·ªÉ d√πng lu·ªìng (threading) 
        # nh∆∞ng ·ªü ƒë√¢y d√πng tr·ª±c ti·∫øp ƒë·ªÉ b·∫°n d·ªÖ hi·ªÉu
        prediction = ocr.predict(ocr_input)
        ocr_rs = list(prediction)

        plate_text = ""
        if ocr_rs and ocr_rs[0]:
            raw_text = "".join([line[1][0] for line in ocr_rs[0]])
            plate_text = re.sub(r'[^0-9A-Z]', '', raw_text.upper())
            
            # L·ªçc nhi·ªÖu
            for noise in ["NAO", "TO", "EEEE", "IEE", "NONE"]:
                plate_text = plate_text.replace(noise, "")

            # V·∫Ω khung v√† ch·ªØ l√™n khung h√¨nh Camera
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"LP: {plate_text}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # In k·∫øt qu·∫£ ra console
            if plate_text:
                print(f"üì∑ Camera Detect: {plate_text}")

    # 5Ô∏è‚É£ Hi·ªÉn th·ªã khung h√¨nh Camera
    cv2.imshow("Nhan dien Bien so Real-time", frame)

    # Nh·∫•n 'q' ƒë·ªÉ tho√°t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
'''