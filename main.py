
import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR
from tkinter import Tk, filedialog

# 1Ô∏è‚É£ Kh·ªüi t·∫°o models
yolo_bienso = YOLO("Bienso.pt")
# Th·ª≠ d√πng lang='ch' ƒë·ªÉ ƒë·ªçc s·ªë chu·∫©n h∆°n n·∫øu 'en' v·∫´n l·ªói
ocr = PaddleOCR(lang='ch', use_textline_orientation=False)


def select_file():
    root = Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    path = filedialog.askopenfilename(title="Ch·ªçn ·∫£nh bi·ªÉn s·ªë xe")
    root.destroy()
    return path


# 2Ô∏è‚É£ Ch·ªçn ·∫£nh
image_path = select_file()
if not image_path:
    print("‚ùå Ch∆∞a ch·ªçn ·∫£nh.");
    exit()

img = cv2.imread(image_path)
results = yolo_bienso(img)[0]

if len(results.boxes.xyxy) == 0:
    print("‚ùå YOLO kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë.")
else:
    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt ·∫£nh t·ª´ YOLO
        crop = img[y1:y2, x1:x2]
        if crop.size == 0: continue

        # --- B√ç K√çP 1: C·∫ÆT R√åA (MARGIN CROP) ---
        # Lo·∫°i b·ªè 10% m·ªói c·∫°nh ƒë·ªÉ x√≥a khung ƒëen v√† l∆∞·ªõi t·∫£n nhi·ªát d√≠nh v√†o
        h_c, w_c = crop.shape[:2]
        margin_h = int(h_c * 0.1)
        margin_w = int(w_c * 0.05)
        crop = crop[margin_h:h_c - margin_h, margin_w:w_c - margin_w]

        # --- B√ç K√çP 2: TI·ªÄN X·ª¨ L√ù NHI·ªÑU ---
        # Ph√≥ng to ·∫£nh
        crop_res = cv2.resize(crop, None, fx=3, fy=3, interpolation=cv2.INTER_LANCZOS4)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)

        # Kh·ª≠ nhi·ªÖu l√†m m·ªãn n·ªÅn
        gray = cv2.fastNlMeansDenoising(gray, h=10)

        # TƒÉng t∆∞∆°ng ph·∫£n (Ch·ªânh clipLimit t·ª´ 10.0 - 40.0 l√† t·ªëi ƒëa)
        clahe = cv2.createCLAHE(clipLimit=20.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # Nh·ªã ph√¢n h√≥a Otsu ƒë·ªÉ l·∫•y ch·ªØ ƒëen tr√™n n·ªÅn tr·∫Øng tinh
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # L√†m d√†y n√©t ch·ªØ m·ªôt ch√∫t ƒë·ªÉ AI d·ªÖ ƒë·ªçc (Morphology)
        kernel = np.ones((2, 2), np.uint8)
        binary = cv2.erode(binary, kernel, iterations=1)

        # Chuy·ªÉn v·ªÅ 3 k√™nh cho AI
        ocr_input = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # HI·ªÇN TH·ªä ·∫¢NH DEBUG
        cv2.imshow(f"AI Vision - Da loc nhieu {idx + 1}", ocr_input)

        # 3Ô∏è‚É£ OCR NH·∫¨N DI·ªÜN
        prediction = ocr.predict(ocr_input)
        ocr_rs = list(prediction)

        plate_text = ""
        if ocr_rs and ocr_rs[0]:
            raw_text = "".join([line[1][0] for line in ocr_rs[0]])

            # L√†m s·∫°ch b·∫±ng Regex
            plate_text = re.sub(r'[^0-9A-Z]', '', raw_text.upper())

            # Lo·∫°i b·ªè c√°c t·ª´ "ma" th∆∞·ªùng g·∫∑p
            for noise in ["NAO", "TO", "EEEE", "IEE", "NONE"]:
                plate_text = plate_text.replace(noise, "")

            # Bi·ªÉn s·ªë VN th∆∞·ªùng d√†i 7-9 k√Ω t·ª±, c·∫Øt b·ªè n·∫øu qu√° d√†i
            plate_text = plate_text[:10]

            print(f"‚úÖ Bi·ªÉn s·ªë: {plate_text} (G·ªëc: {raw_text})")

            # V·∫Ω l√™n ·∫£nh g·ªëc
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img, plate_text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

# 4Ô∏è‚É£ Hi·ªÉn th·ªã k·∫øt qu·∫£
cv2.imshow("Final Result", img)
cv2.waitKey(0)
cv2.destroyAllWindows()
'''

import os
import re
import cv2
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR

# 1Ô∏è‚É£ Kh·ªüi t·∫°o models
yolo_bienso = YOLO("Bienso.pt")
# D√πng lang='ch' ƒë·ªÉ tr√°nh l·ªói EEEE t·ªët h∆°n
ocr = PaddleOCR(lang='ch', use_textline_orientation=False)

# 2Ô∏è‚É£ M·ªü Camera (0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)
cap = cv2.VideoCapture(0)

# C·∫•u h√¨nh ƒë·ªô ph√¢n gi·∫£i camera (T√πy ch·ªçn)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

print("--- ƒêang m·ªü Camera... Nh·∫•n 'q' ƒë·ªÉ tho√°t ---")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # 3Ô∏è‚É£ YOLO Detect tr√™n t·ª´ng khung h√¨nh
    # imgsz=416 gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω real-time
    results = yolo_bienso(frame, conf=0.5, imgsz=416)[0]

    for idx, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)

        # C·∫Øt ·∫£nh bi·ªÉn s·ªë
        crop = frame[y1:y2, x1:x2]
        if crop.size == 0: continue

        # --- X·ª¨ L√ù NHI·ªÑU (T·ªëi ∆∞u cho Camera) ---
        h_c, w_c = crop.shape[:2]
        margin_h = int(h_c * 0.1)
        margin_w = int(w_c * 0.05)
        crop = crop[margin_h:h_c - margin_h, margin_w:w_c - margin_w]

        # Ph√≥ng to v√† x·ª≠ l√Ω ƒêen - Tr·∫Øng
        crop_res = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        gray = cv2.cvtColor(crop_res, cv2.COLOR_BGR2GRAY)
        
        # TƒÉng t∆∞∆°ng ph·∫£n nhanh
        clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        ocr_input = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)

        # 4Ô∏è‚É£ OCR NH·∫¨N DI·ªÜN
        # L∆∞u √Ω: OCR t·ªën t√†i nguy√™n, trong th·ª±c t·∫ø c√≥ th·ªÉ d√πng lu·ªìng (threading) 
        # nh∆∞ng ·ªü ƒë√¢y d√πng tr·ª±c ti·∫øp ƒë·ªÉ b·∫°n d·ªÖ hi·ªÉu
        prediction = ocr.predict(ocr_input)
        ocr_rs = list(prediction)

        plate_text = ""
        if ocr_rs and ocr_rs[0]:
            raw_text = "".join([line[1][0] for line in ocr_rs[0]])
            plate_text = re.sub(r'[^0-9A-Z]', '', raw_text.upper())
            
            # L·ªçc nhi·ªÖu
            for noise in ["NAO", "TO", "EEEE", "IEE", "NONE"]:
                plate_text = plate_text.replace(noise, "")

            # V·∫Ω khung v√† ch·ªØ l√™n khung h√¨nh Camera
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"LP: {plate_text}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
            
            # In k·∫øt qu·∫£ ra console
            if plate_text:
                print(f"üì∑ Camera Detect: {plate_text}")

    # 5Ô∏è‚É£ Hi·ªÉn th·ªã khung h√¨nh Camera
    cv2.imshow("Nhan dien Bien so Real-time", frame)

    # Nh·∫•n 'q' ƒë·ªÉ tho√°t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
'''